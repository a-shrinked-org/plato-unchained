import argparse
import os
import re
import sys
from pathlib import Path
from typing import Callable, Literal, Sequence
from urllib.parse import urlparse

from tqdm import tqdm

import platogram as plato
import platogram.ingest as ingest
from platogram.library import Library
from platogram.types import Assistant, Content, User
from platogram.utils import make_filesystem_safe

CACHE_DIR = Path("./.platogram-cache")

def format_time(ms):
    seconds = ms // 1000
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"

def render_reference(url: str, transcript: list[plato.SpeechEvent], i: int) -> str:
    link = f" [[{i+1}]](#ts-{i + 1})"
    return link
    
def get_chapter(passage_marker: int, chapter_markers: list[int]) -> int | None:
    for start, end in zip(chapter_markers[:-1], chapter_markers[1:]):
        if start <= passage_marker < end:
            return start
    if passage_marker >= chapter_markers[-1]:
        return chapter_markers[-1]
    return None

def render_transcript(first, last, transcript, url):
    return "\n".join(
        [
            f"\n##### {{#ts-{i + 1}}}\n{i-first+1}. [{format_time(event.time_ms)}]({url}#t={event.time_ms // 1000}): {event.text}"
            for i, event in enumerate(transcript)
            if first <= i <= last
        ]
    )

def render_paragraph(p: str, render_reference_fn: Callable[[int], str]) -> str:
    references = sorted([int(i) for i in re.findall(r"【(\d+)】", p)])
    if not references:
        return p

    paragraph = re.sub(
        r"【(\d+)】",
        lambda match: render_reference_fn(int(match.group(1))),
        p,
    )
    return paragraph

def process_url(
    url_or_file: str,
    library: Library,
    args,  # Already added
    anthropic_api_key: str | None = None,
    assemblyai_api_key: str | None = None,
    model_type: str = "gemini",
    extract_images: bool = False,
    lang: str | None = None,
) -> Content | str:  # Adjusted return type to allow str
    """Process a URL or file."""
    print("=== Debug: Process URL Configuration ===")
    print(f"URL: {url_or_file}")
    print(f"Model: {model_type}")
    print(f"Project ID: {os.getenv('GOOGLE_CLOUD_PROJECT')}")
    print(f"Credentials: {os.getenv('GOOGLE_APPLICATION_CREDENTIALS')}")
    print(f"Language: {lang}")
    print("===================================")
    
    # Configure model first to fail fast if credentials are missing
    if model_type == "gemini":
        if not os.getenv("GOOGLE_CLOUD_PROJECT") or not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
            raise ValueError("Missing Gemini credentials")
    elif model_type == "anthropic" and not anthropic_api_key:
        raise ValueError("Missing Anthropic API key")
    
    # Initialize ASR if needed
    asr = None
    if assemblyai_api_key:
        print("Debug: Initializing ASR with AssemblyAI")
        try:
            asr = plato.asr.get_model("assembly-ai/best", assemblyai_api_key)
        except ImportError as e:
            print(f"Warning: {e}")
            print("Continuing without ASR support...")
            asr = None
    
    # Extract transcript
    print("Debug: Starting transcript extraction")
    try:
        if asr:
            transcript = plato.extract_transcript(url_or_file, asr)
        else:
            transcript = plato.extract_transcript(url_or_file, asr, lang=lang)
    except ValueError as e:
        if "No subtitles found and no ASR model provided" in str(e):
            print("Error: Audio file detected but no ASR key provided")
            print("Please provide --assemblyai-api-key or install AssemblyAI with: pip install 'platogram[asr]'")
            raise
        elif "ASR model required for audio files" in str(e):
            print("Error: Audio file detected but no ASR support available")
            print("Please provide --assemblyai-api-key or install AssemblyAI with: pip install 'platogram[asr]'")
            raise
        raise
    
    # Initialize LLM only after successful transcript extraction
    print(f"Debug: Initializing LLM model: {model_type}")
    llm = plato.llm.get_model(
        f"{model_type}/{'gemini-2.0-flash-001' if model_type == 'gemini' else 'claude-3-5-sonnet'}", 
        anthropic_api_key if model_type == "anthropic" else None
    )
    
    # Handle specific flags directly
    if args.title or args.abstract or args.passages or args.chapters or args.references:
        transcript_text = "\n".join(f"[{event.time_ms}ms] {event.text}" for event in transcript)
        if args.title:
            title, _ = llm.get_meta([transcript_text], lang=lang)
            return title  # Just the title text
        elif args.abstract:
            _, abstract = llm.get_meta([transcript_text], lang=lang)
            return abstract  # Just the abstract text
        elif args.passages:
            passages = llm.get_paragraphs(transcript_text, {}, lang=lang)
            return "\n\n".join(passages)
        elif args.chapters:
            chapters = llm.get_chapters([transcript_text], lang=lang)
            return "\n".join(f"• {title} [{i}]" for i, (ms, title) in enumerate(chapters.items()))  # Use raw ms
        elif args.references:
            return "\n".join(f"{i+1}. [{format_time(event.time_ms)}] {event.text}" for i, event in enumerate(transcript))
    
    # Process full content if no specific flags
    content = plato.index(transcript, llm, lang=lang, chunk_size=args.chunk_size)
    content.origin = url_or_file

    if extract_images:
        print("Debug: Extracting images")
        images_dir = library.home / make_filesystem_safe(url_or_file)
        images_dir.mkdir(exist_ok=True)
        timestamps_ms = [event.time_ms for event in content.transcript]
        images = ingest.extract_images(url_or_file, images_dir, timestamps_ms)
        content.images = [str(image.relative_to(library.home)) for image in images]
    
    return content

def prompt_context(
    context: list[Content],
    prompt: Sequence[Assistant | User],
    context_size: Literal["small", "medium", "large"],
    model_type: str = "gemini",
    anthropic_api_key: str | None = None,
) -> str:
    model_name = f"{model_type}/{'gemini-2.0-flash-001' if model_type == 'gemini' else 'claude-3-5-sonnet'}"
    llm = plato.llm.get_model(model_name, anthropic_api_key if model_type == "anthropic" else None)
    
    response = llm.prompt(
        prompt=prompt,
        context=context,
        context_size=context_size,
    )
    return response

def is_uri(s):
    try:
        result = urlparse(s)
        return all([result.scheme, result.netloc, result.path])
    except:
        return False

def main():
    parser = argparse.ArgumentParser(description="Platogram CLI")
    parser.add_argument(
        "inputs",
        nargs="*",
        help="URLs and files to query, if none provided, will use all content",
    )
    parser.add_argument("--lang", help="Content language: en, es")
    parser.add_argument(
        "--model",
        choices=["anthropic", "gemini"],
        default="gemini",
        help="Model to use for processing (default: gemini)"
    )
    parser.add_argument("--anthropic-api-key", help="Anthropic API key")
    parser.add_argument("--assemblyai-api-key", help="AssemblyAI API key (optional)")
    parser.add_argument("--retrieve", default=None, help="Number of results to retrieve")
    parser.add_argument("--generate", action="store_true", help="Generate content")
    parser.add_argument("--query", help="Query for retrieval and generation")
    parser.add_argument(
        "--context-size",
        choices=["small", "medium", "large"],
        default="small",
        help="Context size for prompting",
    )
    parser.add_argument("--title", action="store_true", help="Include title")
    parser.add_argument("--abstract", action="store_true", help="Include abstract")
    parser.add_argument("--passages", action="store_true", help="Include passages")
    parser.add_argument("--chapters", action="store_true", help="Include chapters")
    parser.add_argument("--references", action="store_true", help="Include references")
    parser.add_argument("--images", action="store_true", help="Include images")
    parser.add_argument("--origin", action="store_true", help="Include origin URL")
    parser.add_argument(
        "--retrieval-method",
        choices=["keyword", "semantic", "dumb"],
        default="dumb",
        help="Retrieval method",
    )
    parser.add_argument(
        "--prefill",
        default="",
        help="Nudge the model to continue the provided sentence",
    )
    parser.add_argument(
        "--inline-references", 
        action="store_true", 
        help="Render references inline"
    )
    parser.add_argument(
        "--chunk-size",
        type=int,
        help="Override automatic chunk size for large transcripts (advanced users)"
    )
    
    args = parser.parse_args()
    
    lang = args.lang if args.lang else "en"
    
    if not args.assemblyai_api_key:
        args.assemblyai_api_key = os.getenv("ASSEMBLYAI_API_KEY")
    
    if args.model == "gemini":
        if not os.getenv("GOOGLE_CLOUD_PROJECT"):
            print("Error: GOOGLE_CLOUD_PROJECT environment variable not set")
            sys.exit(1)
        if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
            print("Error: GOOGLE_APPLICATION_CREDENTIALS environment variable not set")
            sys.exit(1)
    
    if args.retrieval_method == "semantic":
        library = plato.library.get_semantic_local_chroma(CACHE_DIR)
    elif args.retrieval_method == "keyword":
        library = plato.library.get_keyword_local_bm25(CACHE_DIR)
    elif args.retrieval_method == "dumb":
        library = plato.library.get_local_dumb(CACHE_DIR)
    else:
        raise ValueError(f"Invalid retrieval method: {args.retrieval_method}")
    
    if not args.inputs:
        ids = library.ls()
        context = [library.get_content(id) for id in ids]
    else:
        ids = [make_filesystem_safe(url_or_file) for url_or_file in args.inputs]
        context = [
            process_url(
                url_or_file,
                library,
                args,
                args.anthropic_api_key,
                args.assemblyai_api_key,
                args.model,
                extract_images=args.images,
                lang=lang,
            )
            for url_or_file in args.inputs
        ]
    
    if args.retrieval_method == "keyword":
        library.put(ids[0], context[0])
    
    if args.retrieve:
        n_results = int(args.retrieve)
        context, scores = library.retrieve(args.query, n_results, ids)
    
    result = ""
    
    if args.generate:
        if not args.query:
            raise ValueError("Query is required for generation")
        
        prompt = [User(content=args.query)]
        if args.prefill:
            prompt = [User(content=args.query), Assistant(content=args.prefill)]
        
        # Handle the case where prompt_context returns a string directly
        generated_output = prompt_context(
            context=context,
            prompt=prompt,
            context_size=args.context_size,
            model_type=args.model,
            anthropic_api_key=args.anthropic_api_key
        )
        result += f"\n\n{generated_output}\n\n"
    
    # Process each item in context, handling both strings and Content objects
    for item in context:
        if item is None:
            continue  # Skip if item is None
    
        if isinstance(item, str):
            # If the item is a string (e.g., from --title or --abstract), use it directly
            result += f"{item}\n\n\n\n"
            continue  # Move to the next item after handling the string
    
        # If the item is a Content object, process its attributes
        content = item
        
        if args.images and content.images:
            images = "\n".join([str(image) for image in content.images])
            result += f"{images}\n\n\n\n"
    
        if args.origin:
            result += f"{content.origin}\n\n\n\n"
    
        if args.title:
            result += f"{content.title}\n\n\n\n"
    
        if args.abstract:
            result += f"{content.summary}\n\n\n\n"
    
        if args.passages:
            passages = ""
            if args.chapters:
                current_chapter = None
                chapter_markers = list(content.chapters.keys())
                for passage in content.passages:
                    passage_markers = [int(m) for m in re.findall(r"【(\d+)】", passage)]
                    chapter_marker = get_chapter(passage_markers[0], chapter_markers) if passage_markers else None
                    if chapter_marker is not None and chapter_marker != current_chapter:
                        passages += f"### {content.chapters[chapter_marker]}\n\n"
                        current_chapter = chapter_marker
                    passages += f"{passage.strip()}\n\n"
            else:
                passages = "\n\n".join(passage.strip() for passage in content.passages)
            result += f"{passages}\n\n\n\n"
    
        if args.chapters and not args.passages:
            chapters = "\n".join(f"- {chapter} [{i}]" for i, chapter in content.chapters.items())
            result += f"{chapters}\n\n\n\n"
    
        if args.references:
            result += f"{render_transcript(0, len(content.transcript), content.transcript, content.origin)}\n\n\n\n"
    
        if args.inline_references:
            render_reference_fn = lambda i: render_reference(content.origin or "", content.transcript, i)
        else:
            render_reference_fn = lambda _: ""
    
        result = render_paragraph(result, render_reference_fn)
    
    print(result.strip())  # Strip trailing whitespace for cleaner output

if __name__ == "__main__":
    main()